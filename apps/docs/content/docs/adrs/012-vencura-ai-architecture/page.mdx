---
title: "ADR 012: Vencura AI Architecture"
description: "We need to add AI-powered chatbot functionality to the Vencura wallet platform that provides natural language interface, is embeddable in React/Next.js applications, and maintains portability."
---

# ADR 012: Vencura AI Architecture

## Context

We need to add AI-powered chatbot functionality to the Vencura wallet platform. The chatbot should:

- Provide natural language interface for wallet operations
- Be embeddable in any React/Next.js application
- Support voice input
- Expose wallet operations as AI tools
- Maintain portability and avoid vendor lock-in
- Work seamlessly with existing authentication and API infrastructure

## Considered Options

### Option A – Vercel AI SDK with Vercel Functions

Use Vercel AI SDK with serverless functions for AI inference.

**Pros**

- Zero infrastructure setup
- Built-in streaming support
- Excellent developer experience
- Tight integration with Vercel AI SDK

**Cons**

- Vendor lock-in to Vercel platform
- Limited runtime duration (max 10 min, Edge ≤ 30s)
- Cannot maintain persistent connections or state
- Difficult to integrate with existing NestJS wallet services
- Not suitable for long-running wallet operations
- Cannot easily migrate to other platforms

### Option B – NestJS-First with AI SDK Core

Use NestJS backend with `@ai-sdk/core` for provider-agnostic AI integration.

**Pros**

- Full control over wallet operations and security
- Portable to any platform (GCP Cloud Run, AWS, Fly.io, self-hosted)
- Can maintain state and persistent connections
- Seamless integration with existing wallet services
- Standard SSE streaming works everywhere
- No vendor lock-in
- Can orchestrate multiple AI providers
- Better for wallet security and compliance

**Cons**

- More setup required for streaming
- Slightly more latency than edge functions
- Requires manual SSE implementation

### Option C – Hybrid (Vercel Edge + NestJS)

Use Vercel Edge for AI inference, NestJS for wallet operations.

**Pros**

- Fast AI inference on edge
- Full control over wallet operations
- Can scale AI layer independently

**Cons**

- More complex architecture
- Still has Vercel lock-in for AI layer
- Additional network hops between services
- More operational complexity

## Decision

We will use **Option B: NestJS-First with AI SDK Core**.

**Main reasons:**

- **Portability**: No vendor lock-in - can deploy to GCP Cloud Run, AWS, Fly.io, or self-hosted
- **Control**: Full control over wallet operations, state management, and security
- **Integration**: Seamless integration with existing NestJS wallet services
- **Security**: Better for wallet operations requiring secure, stateful backends
- **Flexibility**: Can switch AI providers or add multiple providers without architectural changes
- **Standards**: Standard SSE streaming implementation works on any platform

## Architecture

### Package Structure

```
packages/vencura-ai/
├── src/
│   ├── sdk/              # TypeScript SDK for agentic integration
│   ├── components/        # React components (Chatbot, VoiceInput)
│   └── hooks/             # React hooks (useChatbot, useVoiceInput)
```

### Peer Dependencies

The `@vencura/ai` package uses peer dependencies to avoid bundling and maintain flexibility:

- `@vencura/core` - API client (provided by consumer app via VencuraProvider)
- `@vencura/react` - VencuraProvider wrapper (consumer app provides)
- `@dynamic-labs/sdk-react-core` - Dynamic authentication (consumer app provides)

This ensures:

- Smaller bundle size
- No circular dependencies
- Consumer app controls API client configuration
- Authentication handled by consumer app

### Backend Implementation

**Chat Endpoint**: `POST /chat` with SSE streaming support

**Tool Integration**: Wallet operations exposed as AI tools:

- `getWallets` - List user wallets
- `createWallet` - Create new wallet
- `getBalance` - Get wallet balance
- `sendTransaction` - Send transaction
- `signMessage` - Sign message

**Streaming**: Server-Sent Events (SSE) for real-time chat responses

**Authentication**: Reuses existing `AuthGuard` and user context

### Frontend Implementation

**React Component**: `<Chatbot />` - Embeddable chatbot UI

**Features**:

- Uses Vercel AI Elements for UI components
- Voice input via Web Speech API
- Mobile-first responsive design
- Works in sidebar, modal, or fullscreen

**Hooks**:

- `useChatbot` - Chat state management
- `useVoiceInput` - Voice recognition

## Implementation Details

### Streaming

Uses NestJS `@Res()` decorator with SSE response:

```typescript
res.setHeader('Content-Type', 'text/event-stream')
res.setHeader('Cache-Control', 'no-cache')
res.setHeader('Connection', 'keep-alive')

const result = await chatService.streamChat(messages, userId)
for await (const chunk of result.textStream) {
  res.write(`data: ${JSON.stringify({ content: chunk })}\n\n`)
}
```

### Tool Execution

Tools are defined using `@ai-sdk/core` `tool()` function:

```typescript
createWallet: tool({
  description: 'Create a new wallet',
  parameters: z.object({ chainId: z.union([z.number(), z.string()]) }),
  execute: async ({ chainId }) => walletService.createWallet(userId, chainId),
})
```

### Authentication

- Consumer app provides `VencuraProvider` with auth headers
- Chatbot component uses `useDynamicContext()` for auth state
- Backend uses existing `AuthGuard` for endpoint protection

## Portability Considerations

### Why Not Supabase SDK?

We considered using Supabase SDK for portability, but decided against it because:

- **NestJS Integration**: Our existing infrastructure is NestJS-based
- **Control**: Direct database access gives us more control over queries and transactions
- **Flexibility**: Can use any database (PostgreSQL, Cloud SQL, PGLite) without SDK dependency
- **Performance**: Direct database access is more performant than SDK abstraction
- **Migration**: Easier to migrate between providers without SDK lock-in

### Deployment Options

The NestJS backend can be deployed to:

- **Google Cloud Run**: Serverless containers with auto-scaling
- **AWS Lambda/ECS**: Serverless or containerized
- **Fly.io**: Global edge deployment
- **Self-hosted**: VPS, dedicated servers, on-premises
- **Vercel**: Serverless functions (current deployment)

All use standard SSE streaming - no platform-specific code required.

## Future Considerations

- **Multiple AI Providers**: Can easily add Anthropic, Cloudflare AI, or local models
- **Tool Expansion**: Add more wallet operations as tools (multi-sig, batch transactions)
- **Caching**: Add response caching for common queries
- **Rate Limiting**: Per-user rate limiting for AI requests
- **Analytics**: Track tool usage and user queries

## Notes

- OpenAI API key configured via `OPEN_AI_KEY` environment variable
- Chat endpoint rate-limited to 30 requests per minute per user
- Tools execute with user context for proper authorization
- Voice input uses browser-native Web Speech API (graceful degradation)
- Component is mobile-first and responsive
- All code follows existing patterns and conventions

## Related ADRs

- [ADR 002: Vencura API Framework](/docs/adrs/002-vencura-api-framework) - NestJS framework decision
- [ADR 010: Vencura Infrastructure Orchestration](/docs/adrs/010-vencura-infra-orchestration) - Deployment strategy
- [ADR 011: Vencura API ORM Selection](/docs/adrs/011-vencura-api-orm) - Database ORM decision
